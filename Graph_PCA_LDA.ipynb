{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66a7ba3",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>Graph Kernel PCA + LDA Classification </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4bfc8e",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "In this notebook, we train and evaluate an LDA classifier while we apply a graph-based kernel PCA.\n",
    "<br>   \n",
    "    \n",
    "Our datasets are regression problems, nevertheless, our target value range (0-1) helped us to solve the problem as a classification task. Where we rounded the target values and managed them as classes. The main reason that we use regression datasets is described in the report.\n",
    "    \n",
    "In more detail:   \n",
    "- We use the PropagationAttr model for computing kernels with graph data. \n",
    "- PropagationAttr return adjacency matrixes of shape (num_of_grpahs,num_of_grpahs) for train and test.   \n",
    "- We use these adjacency matrixes as input for a PCA model with a precomputed kernel.   \n",
    "- The output of the KPCA model is an array with shape (num_of_grpahs,n_components).\n",
    "- We use PCA output in order to feed it an LDA classifier using target with the shape of (num_of_grpahs,num_of_nodes)\n",
    "- We make several experiments using different hyper-parameters for both KPCA and LDA models. \n",
    "    \n",
    "    Ps: We use ParkingViolation and Chickenpox datasets for our experiments   \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07882c1",
   "metadata": {},
   "source": [
    "## Generals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf5800e",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Packages import and system configurations. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from grakel.kernels import PropagationAttr\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime as dt\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "cores = multiprocessing.cpu_count()-2\n",
    "project_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe7daf",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Datasets paths. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f830a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parking Violation\n",
    "G_train_path_park = project_path + '/Data/ParkingViolationPrediction_PCA_LDA/G_Train.pkl'\n",
    "G_test_path_park = project_path + '/Data/ParkingViolationPrediction_PCA_LDA/G_Test.pkl'\n",
    "test_targets_path_park = project_path + '/Data/ParkingViolationPrediction_PCA_LDA/Init/Test_Targets.csv'\n",
    "train_targets_path_park = project_path + '/Data/ParkingViolationPrediction_PCA_LDA/Init/Train_Targets.csv'\n",
    "test_mask_path_park = project_path + '/Data/ParkingViolationPrediction_PCA_LDA/Init/Test_Mask.csv'\n",
    "K_train_park = project_path +'/Data/ParkingViolationPrediction_PCA_LDA/K_train.npy'\n",
    "K_test_park = project_path +'/Data/ParkingViolationPrediction_PCA_LDA/K_test.npy'\n",
    "\n",
    "#Chickenpox\n",
    "G_train_path_chic = project_path + '/Data/Chickenpox/G2_Train.pkl'\n",
    "G_test_path_chic = project_path + '/Data/Chickenpox/G2_Test.pkl'\n",
    "test_targets_path_chic = project_path + '/Data/Chickenpox/Init/Chickenpox_Test_targets.csv'\n",
    "train_targets_path_chic = project_path + '/Data/Chickenpox/Init/Chickenpox_Train_targets.csv'\n",
    "test_mask_path_chic = None\n",
    "K_train_chickenpox = project_path +'/Data/Chickenpox/K_train_ch.npy'\n",
    "K_test_chickenpox = project_path +'/Data/Chickenpox/K_test_ch.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6c646b",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c25421",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that takes as input the data paths and return the data.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b26e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(G_train_path,G_test_path,test_targets_path,train_targets_path,use_test_mask,test_mask_path):\n",
    "    with open(G_train_path, 'rb') as inp:\n",
    "        G_train = pickle.load(inp)\n",
    "    with open(G_test_path, 'rb') as inp:\n",
    "        G_test = pickle.load(inp)\n",
    "        \n",
    "    y_train = pd.read_csv(train_targets_path,sep=',', index_col=0)\n",
    "    y_test = pd.read_csv(test_targets_path,sep=',', index_col=0)\n",
    "    if use_test_mask:\n",
    "        test_mask = pd.read_csv(test_mask_path,index_col=0)\n",
    "    else:\n",
    "        test_mask = None\n",
    "    return G_train,G_test,y_train,y_test,test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6b7b2c",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that takes the datasets and return a subset for each data accoriding the given data-sizes.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(G_train,G_test,y_train,y_test,use_test_mask,test_mask,train_size,test_size):\n",
    "    G_train = G_train[0:train_size]\n",
    "    G_test = G_test[0:test_size]\n",
    "    y_train = y_train.iloc[:,:train_size]\n",
    "    y_test = y_test.iloc[:,:test_size]\n",
    "    if use_test_mask:\n",
    "        test_mask = test_mask.iloc[:,:test_size]\n",
    "    else:\n",
    "        test_mask = None\n",
    "    return G_train,G_test,y_train,y_test,test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83332a4",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that get subset of the data if the given variable is True and reshape the targets to the necessary shape.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68390cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(G_train,G_test,y_train,y_test,use_test_mask,test_mask,subset,train_size,test_size):\n",
    "    if subset:\n",
    "        G_train,G_test,y_train,y_test,test_mask = get_subset(G_train,G_test,y_train,y_test,use_test_mask,test_mask,train_size,test_size)\n",
    "\n",
    "    y_train = np.array(y_train.T)\n",
    "    y_test = np.array(y_test.T)\n",
    "    if use_test_mask:\n",
    "        test_mask = np.array(test_mask.T)\n",
    "    else:\n",
    "        test_mask = None\n",
    "    return G_train,G_test,y_train,y_test,test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e994c56",
   "metadata": {},
   "source": [
    "## Main functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54020094",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that calculates the Mean Absolute Error (MAE) and Mean Squared Error (MSE) between predictions and actual targets for train and test sets. \n",
    "In case of Parking data, it uses a mask in order to calculate the errors only for the raw targets.\n",
    "    <br>\n",
    "    \n",
    "Although we have transformed our problem as a classification task, we assign classes to it as integers and compute metrics that are applied to regression tasks.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd609ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_on_actuals(eval_set,y_pred,y_test,use_test_mask,test_mask):\n",
    "    \n",
    "    if eval_set == 'test':\n",
    "        pred = []\n",
    "        actual = []\n",
    "        if use_test_mask:\n",
    "            for i in range(0,(len(y_pred))):\n",
    "                for k in range (0,len(y_pred[0])):\n",
    "                    if test_mask[i][k] == 1:\n",
    "                        prd = (y_pred[i][k]/100)\n",
    "                        pred.append(float(prd))\n",
    "                        act = (y_test[i][k]/100)\n",
    "                        actual.append(float(act))\n",
    "        else:\n",
    "            for i in range(0,(len(y_pred))):\n",
    "                for k in range (0,len(y_pred[0])):\n",
    "                    prd = (y_pred[i][k]/100)\n",
    "                    pred.append(float(prd))\n",
    "                    act = (y_test[i][k]/100)\n",
    "                    actual.append(float(act))\n",
    "    \n",
    "    elif eval_set == 'train':\n",
    "        pred = []\n",
    "        actual = []\n",
    "        for i in range(0,(len(y_pred))):\n",
    "            for k in range (0,len(y_pred[0])):\n",
    "                prd = (y_pred[i][k]/100)\n",
    "                pred.append(float(prd))\n",
    "                act = (y_test[i][k]/100)\n",
    "                actual.append(float(act))   \n",
    "        \n",
    "        \n",
    "    MAE = round(metrics.mean_absolute_error(actual, pred),5)\n",
    "    print (f\"The Mean Abslolute Error (MAE) that have been calculated for {eval_set} set is: {MAE}\")\n",
    "    MSE = round(metrics.mean_squared_error(actual, pred),5)\n",
    "    print (f\"The Mean Squared Error (MSE) that have been calculated for {eval_set} set is: {MSE}\")\n",
    "    return MAE,MSE,pred,actual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4cd22c",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that converts our target values to classes.\n",
    "\n",
    "In more detail, it scales target column from range (0-1) to (1-100)  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c308fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_to_classes(df):\n",
    "    df = df.round(decimals=2)\n",
    "    df = df * 100\n",
    "    df = df.astype('int')\n",
    "    unique_classes = np.unique(df)\n",
    "    return df,unique_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe2155",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that applies kernel computation using PropagationAttr model.\n",
    "\n",
    "Function fit and saves adjacency matrixes or loads them according to the given instruction\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_kernel_computation(fit,G_train,G_test,K_train_path,K_test_path):\n",
    "    if fit:\n",
    "        graph_kernels = PropagationAttr(t_max=10,w=20,M='L2',n_jobs=cores)\n",
    "        graph_kernels.fit(G_train)\n",
    "        K_train = graph_kernels.transform(G_train)\n",
    "        K_test = graph_kernels.transform(G_test)\n",
    "        with open(K_train_path, 'wb') as f:\n",
    "             np.save(f, K_train)\n",
    "        with open(K_test_path, 'wb') as f:\n",
    "             np.save(f, K_test)\n",
    "    else:\n",
    "        with open(K_train_path, 'rb') as f:\n",
    "             K_train = np.load(f)\n",
    "        with open(K_test_path, 'rb') as f:\n",
    "             K_test = np.load(f)\n",
    "        \n",
    "    return K_train,K_test    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e41422c",
   "metadata": {},
   "source": [
    "## Kenel PCA Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803265c0",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that helps us to define the best 'n_components' value\n",
    "    \n",
    "In more detail:\n",
    "- Fit a precomputed Kernel PCA model using the given 'n_components'.\n",
    "- Use KPCA outputs in order to fit an MultiOutput LDA model (default hyper parameter)\n",
    "- Calculate the necessary metrics in order to find the best n_components\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kpca(G_train,G_test,y_train,y_test,use_test_mask,test_mask,cores,N,K_train_path,K_test_path):\n",
    "    start = dt.now()\n",
    "    K_train,K_test = graph_kernel_computation(False,G_train,G_test,K_train_path,K_test_path)\n",
    "    transformer = KernelPCA(kernel='precomputed',n_components=N )\n",
    "    X_train_transformed = transformer.fit_transform(K_train)\n",
    "    X_test_transformed = transformer.transform(K_test)\n",
    "    \n",
    "    y_train,unique_classes_train = values_to_classes(y_train)\n",
    "    y_test,unique_classes_test = values_to_classes(y_test)\n",
    "    LDA = LinearDiscriminantAnalysis()\n",
    "    LDA_Mclassifier = MultiOutputClassifier(LDA)\n",
    "    \n",
    "    LDA_Mclassifier.fit(X_train_transformed, y_train)\n",
    "    running_secs = (dt.now() - start).seconds\n",
    "    print (f\"\\nLDA Model with PCA (n_components={N}) have fitted succesfully in {(dt.now() - start).seconds} seconds\")\n",
    "    \n",
    "    y_train_pred = LDA_Mclassifier.predict(X_train_transformed)\n",
    "    train_MAE,train_MSE,train_pred,train_actual = calculate_metrics_on_actuals('train',y_train_pred,y_train,use_test_mask,test_mask)\n",
    "    \n",
    "    y_pred = LDA_Mclassifier.predict(X_test_transformed)\n",
    "    MAE,MSE,pred,actual = calculate_metrics_on_actuals('test',y_pred,y_test,use_test_mask,test_mask)\n",
    "    \n",
    "    return MAE,MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de827a76",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that feed the above pipeline with different values of 'n_components' while saves the evaluation results.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19068b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpca_evaluation_results(G_train,G_test,y_train,y_test,use_test_mask,test_mask,cores,\n",
    "                           n_components,K_train_park,K_test_park):\n",
    "    \n",
    "    all_mae = []\n",
    "    all_mse = []\n",
    "    for i in range(0,len(n_components)):\n",
    "        MAE,MSE = evaluate_kpca(G_train,G_test,y_train,y_test,use_test_mask,test_mask,cores,n_components[i],\n",
    "                               K_train_park,K_test_park)\n",
    "        all_mae.append(MAE)\n",
    "        all_mse.append(MSE)\n",
    "    pca_results={'n_components':n_components,'MAE':all_mae,'MSE':all_mse}\n",
    "    min_mae = min(pca_results['MAE'])\n",
    "    min_index = pca_results['MAE'].index(min_mae)\n",
    "    best_n_components = pca_results['n_components'][min_index]\n",
    "    return pca_results,best_n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ccb09",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that plots the results of experiments involving finding the best hyper-parameter of 'n_components'\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f5dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kpca(pca_results,data_name):\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    fig.suptitle('N_components infulence on PCA')    \n",
    "    ax1.plot(range(1, len(pca_results['n_components']) + 1), pca_results['MAE'],label='MAE', color=\"blue\")\n",
    "    ax2.plot(range(1, len(pca_results['n_components']) + 1), pca_results['MSE'],label='MSE', color=\"orange\")\n",
    "    \n",
    "    ax1.set(ylabel='MAE')\n",
    "    ax2.set(ylabel='MSE')\n",
    "    plt.xlabel('n_components', fontsize=12)\n",
    "    plt.savefig('Exports/n_componets_Graph_PCA_' + data_name + '.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67a0df",
   "metadata": {},
   "source": [
    "## LDA evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b0d5ce",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that helps us to define the best hyper-parameters of LDA model \n",
    "    \n",
    "In more detail:\n",
    "- Fit a precomputed Kernel PCA model using the best 'n_components' found above.\n",
    "- Use KPCA outputs in order to fit an MultiOutput LDA model with the given param_grid\n",
    "- Calculate the necessary metrics in order to find the best hyper-parameters\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lda(G_train,G_test,y_train,y_test,use_test_mask,test_mask,cores,param_grid,\n",
    "                 best_n_components,K_train_path,K_test_path):\n",
    "    \n",
    "    K_train,K_test = graph_kernel_computation(False,G_train,G_test,K_train_path,K_test_path)\n",
    "    \n",
    "    start = dt.now()\n",
    "    transformer = KernelPCA(kernel='precomputed',n_components=best_n_components)\n",
    "    X_train_transformed = transformer.fit_transform(K_train)\n",
    "    X_test_transformed = transformer.transform(K_test)\n",
    "\n",
    "    y_train,unique_classes_train = values_to_classes(y_train)\n",
    "    y_test,unique_classes_test = values_to_classes(y_test)\n",
    "    \n",
    "    LDA = LinearDiscriminantAnalysis(**param_grid)\n",
    "    LDA_Mclassifier = MultiOutputClassifier(LDA)\n",
    "    LDA_Mclassifier.fit(X_train_transformed,y_train)\n",
    "    running_secs = (dt.now() - start).seconds\n",
    "    print (f\"LDA Model have fitted succesfully in {running_secs} seconds\")\n",
    "    \n",
    "    y_train_pred = LDA_Mclassifier.predict(X_train_transformed)\n",
    "    train_MAE,train_MSE,train_pred,train_actual = calculate_metrics_on_actuals('train',y_train_pred,y_train,use_test_mask,test_mask)\n",
    "    \n",
    "    y_pred = LDA_Mclassifier.predict(X_test_transformed)\n",
    "    MAE,MSE,pred,actual = calculate_metrics_on_actuals('test',y_pred,y_test,use_test_mask,test_mask)\n",
    "    \n",
    "    return MAE,MSE,running_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d737a9b3",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that feed the above pipeline with different LDA hyper-parameters while saves the evaluation results.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_evaluation_results(G_train,G_test,y_train,y_test,use_test_mask,test_mask,cores,param_grid,\n",
    "                                     best_n_components,K_train_path,K_test_path):\n",
    "    \n",
    "    lda_results = []\n",
    "    for i in range(0,len(param_grid)):\n",
    "        print (f\"\\nParameters: {list(param_grid)[i]}\")\n",
    "        MAE,MSE,running_secs = evaluate_lda(G_train,G_test,y_train,y_test,use_test_mask,test_mask,cores,param_grid[i],\n",
    "                               best_n_components,K_train_path,K_test_path)\n",
    "        lda_results.append({'Parameters':param_grid[i],'MAE':MAE,'MSE':MSE,'Training Time':running_secs})\n",
    "    lda_results = pd.DataFrame(lda_results)\n",
    "    lda_results = lda_results.sort_values(by=['MAE'])\n",
    "    lda_results = lda_results.reset_index()\n",
    "    lda_results = lda_results.drop(['index'], axis=1)\n",
    "    return lda_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb5725",
   "metadata": {},
   "source": [
    "## 1. Functionality Combinations for Parking Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894218f3",
   "metadata": {},
   "source": [
    "### 1.1 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train,G_test,y_train,y_test,test_mask = data_load(G_train_path_park,G_test_path_park,test_targets_path_park,\n",
    "                                                    train_targets_path_park,True,test_mask_path_park)\n",
    "\n",
    "G_train,G_test,y_train,y_test,test_mask = data_preprocess(G_train,G_test,y_train,y_test,True,test_mask,\n",
    "                                                          False,1000,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d5c5e",
   "metadata": {},
   "source": [
    "### 1.2 KPCA Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45b45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_park = np.arange(1,14,1)\n",
    "pca_results_park,best_n_components_park = kpca_evaluation_results(G_train,G_test,y_train,y_test,True,test_mask,cores,\n",
    "                                 n_components_park,K_train_park,K_test_park)\n",
    "plot_kpca(pca_results_park,'Parking')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb3c22",
   "metadata": {},
   "source": [
    "### 1.3 LDA evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d1a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_park = [{\"solver\":['svd'],'store_covariance':[False,True],'tol':[0.5,0.05]},\n",
    "                {\"solver\":['lsqr','eigen'],'shrinkage':['auto',None,0.2,0.4]}]\n",
    "param_grid_park = ParameterGrid(parameters_park)\n",
    "lda_results_park = lda_evaluation_results(G_train,G_test,y_train,y_test,True,test_mask,cores,param_grid_park,\n",
    "                                     best_n_components_park,K_train_park,K_test_park)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acec2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_results_park"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f049e4",
   "metadata": {},
   "source": [
    "## 2. Functionality Combinations for ChickenPox Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c6b26",
   "metadata": {},
   "source": [
    "### 2.1 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15387b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train,G_test,y_train,y_test,test_mask = data_load(G_train_path_chic,G_test_path_chic,test_targets_path_chic,\n",
    "                                                    train_targets_path_chic,False,test_mask_path_chic)\n",
    "G_train,G_test,y_train,y_test,test_mask = data_preprocess(G_train,G_test,y_train,y_test,False,test_mask,\n",
    "                                                          False,250,60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72df6aa",
   "metadata": {},
   "source": [
    "### 2.2 KPCA Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7154469",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_chi = np.arange(1,5,1)\n",
    "pca_results_chi,best_n_components_chi = kpca_evaluation_results(G_train,G_test,y_train,y_test,False,test_mask,cores,\n",
    "                                 n_components_chi,K_train_chickenpox,K_test_chickenpox)\n",
    "plot_kpca(pca_results_chi,'Chickenpox')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ca8e1",
   "metadata": {},
   "source": [
    "### 1.3 LDA evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e370431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_chi = [{\"solver\":['svd'],'store_covariance':[False,True],'tol':[0.5,0.05]},\n",
    "                {\"solver\":['lsqr','eigen'],'shrinkage':['auto',None,0.2,0.4]}]\n",
    "param_grid_chi = ParameterGrid(parameters_chi)\n",
    "lda_results_chi = lda_evaluation_results(G_train,G_test,y_train,y_test,False,test_mask,cores,param_grid_chi,\n",
    "                                     best_n_components_chi,K_train_chickenpox,K_test_chickenpox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_results_chi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full_ml",
   "language": "python",
   "name": "full_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
