{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32007023",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center> Experiments with PCA Kernels and LDA</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc8084",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "In notebook, we train and test various MultiOutput Classifiers (PCA kernels + LDA) from the sklearn library.\n",
    "\n",
    "- All experiments were done in non-graph-based approaches where the information on edges and edge weights was not used.\n",
    "    \n",
    "- The data were converted to a common dataframe format and we use only the raw data for testing.\n",
    "\n",
    "- Our datasets are regression problems, nevertheless, our target value range (0-1) helped us to solve the problem as a classification task. Where we rounded the target values and managed them as classes. The main reason that we use regression datasets is described in the report.\n",
    "    \n",
    "In summary, this notebook was created in order to compare the sklearn models with our graph kernel PCA technique.\n",
    "    \n",
    "     Ps: We use ParkingViolation and Chickenpox datasets for our experiments  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f79e1d",
   "metadata": {},
   "source": [
    "## Generals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3260275",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Packages import and system configurations. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime as dt\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "\n",
    "cores = multiprocessing.cpu_count()-2\n",
    "project_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe7804",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Datasets paths. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea81030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ParkingViolation\n",
    "train_set_path_park = project_path + '/Data/ParkingViolationPrediction_PCA_LDA/Init/Train_Dataset_Graph.pkl'\n",
    "test_set_path_park = project_path + '/Data/ParkingViolationPrediction_PCA_LDA/Init/Test_Dataset_Graph.pkl'\n",
    "train_targets_path_park = project_path + '/Data/ParkingViolationPrediction_PCA_LDA/Init/Train_Targets.csv'\n",
    "test_targets_path_park = project_path + '/Data/ParkingViolationPrediction_PCA_LDA/Init/Test_Targets.csv'\n",
    "train_mask_path_park = project_path + '/Data/ParkingViolationPrediction_PCA_LDA/Init/Train_Mask.csv'\n",
    "test_mask_path_park = project_path + '/Data/ParkingViolationPrediction_PCA_LDA/Init/Test_Mask.csv'\n",
    "\n",
    "#ChickePox\n",
    "train_set_path_chic = project_path + '/Data/Chickenpox/Init/Chickenpox_Train_data.pkl'\n",
    "test_set_path_chic = project_path + '/Data/Chickenpox/Init/Chickenpox_Test_data.pkl'\n",
    "train_targets_path_chic = project_path + '/Data/Chickenpox/Init/Chickenpox_Train_targets.csv'\n",
    "test_targets_path_chic = project_path + '/Data/Chickenpox/Init/Chickenpox_Test_targets.csv'\n",
    "train_mask_path_chic = None\n",
    "test_mask_path_chic = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591002b",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34dec07",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that takes as input the data paths and return the data or a subset of them.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd8f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(train_set_path,test_set_path,train_targets_path,test_targets_path,use_mask,train_mask_path,test_mask_path,subset,train_size,test_size):\n",
    "    with open(train_set_path, 'rb') as inp:\n",
    "        train_set = pickle.load(inp)\n",
    "    with open(test_set_path, 'rb') as inp:\n",
    "        test_set = pickle.load(inp)\n",
    "      \n",
    "    train_targets = pd.read_csv(train_targets_path,index_col=0)\n",
    "    test_targets = pd.read_csv(test_targets_path,index_col=0)\n",
    "    if use_mask:\n",
    "        train_mask = pd.read_csv(train_mask_path,index_col=0)\n",
    "        test_mask = pd.read_csv(test_mask_path,index_col=0)\n",
    "    else:\n",
    "        train_mask = None\n",
    "        test_mask = None \n",
    "        \n",
    "    if subset:\n",
    "        train_set,test_set,train_targets,test_targets,train_mask,test_mask = get_subset(train_set,test_set,\n",
    "                                        train_targets,test_targets,use_mask,train_mask,test_mask,train_size,test_size)\n",
    "    \n",
    "    return train_set,test_set,train_targets,test_targets,train_mask,test_mask  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948528fc",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that takes the datasets and return a subset for each data accoriding the given data-sizes.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2153e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(train_set,test_set,train_targets,test_targets,use_mask,train_mask,test_mask,train_size,test_size):\n",
    "    train_set = train_set[0:train_size]\n",
    "    test_set = test_set[0:test_size]\n",
    "    train_targets = train_targets.iloc[:,:train_size]\n",
    "    test_targets = test_targets.iloc[:,:test_size]\n",
    "    if use_mask:\n",
    "        train_mask = train_mask.iloc[:,:train_size]\n",
    "        test_mask = test_mask.iloc[:,:test_size]\n",
    "    else:\n",
    "        train_mask = None\n",
    "        test_mask = None\n",
    "        \n",
    "    return train_set,test_set,train_targets,test_targets,train_mask,test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4776247c",
   "metadata": {},
   "source": [
    "## Main functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933f150",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that converts our target values to classes.\n",
    "\n",
    "In more detail, it scales target column from range (0-1) to (1-100)  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53412676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_to_classes(df):\n",
    "    df = df.round(decimals=2)\n",
    "    df = df * 100\n",
    "    df = df.astype('int')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf010c",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function takes a list of dataframes that descibes the features, a dataframe with the targets and a mask.\n",
    "\n",
    "Return only the raw X and y on dataframe format.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(data_set,y,mask):\n",
    "    names = ['Date_Sin','Holidays','Capacity','temp','humidity','Week_Day_Sin','Month_Sin','Real_Time','Γενικό Νοσοκομείο Θεσσαλονίκης «Γ. Γεννηματάς»', 'Λιμάνι' ,'Δημαρχείο Θεσσαλονίκης','Λευκός Πύργος','Αγορά Καπάνι','Λαδάδικα','Πλατεία Άθωνος','Πλατεία Αριστοτέλους','Ροτόντα','Πλατεία Αγίας Σοφίας','Πλατεία Αντιγονιδών','Μουσείο Μακεδονικού Αγώνα','Πλατεία Ναυαρίνου','Πάρκο ΧΑΝΘ','Ιερός Ναός Αγίου Δημητρίου','ΔΕΘ','ΑΠΘ','Άγαλμα Ελευθερίου Βενιζέλου','Ρωμαϊκή Αγορά Θεσσαλονίκης','Predictions']\n",
    "    for i in tqdm (range (0,len(data_set))):\n",
    "        data_set[i] = data_set[i].sort_values(\"Slot_id\")\n",
    "        data_set[i] = data_set[i].set_index(\"Slot_id\")\n",
    "        data_set[i] = data_set[i][names]\n",
    "        \n",
    "        data_set[i] = data_set[i].join(y.iloc[:,i])\n",
    "        data_set[i] = data_set[i].set_axis([*data_set[i].columns[:-1], 'Target'], axis=1, inplace=False)\n",
    "        \n",
    "        data_set[i] = data_set[i].join(mask.iloc[:,i])\n",
    "        data_set[i] = data_set[i].set_axis([*data_set[i].columns[:-1], 'Mask'], axis=1, inplace=False)\n",
    "        \n",
    "        data_set[i] = data_set[i].loc[data_set[i]['Mask'] == 1]\n",
    "        \n",
    "    data_set = pd.concat(data_set).reset_index()\n",
    "    data_set = data_set.drop(['Mask','Slot_id'], axis=1)\n",
    "    \n",
    "    X = data_set.drop(['Target'], axis=1)\n",
    "    y = values_to_classes(data_set['Target'])\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c1f9c",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that converts our target classes to values.\n",
    "\n",
    "In more detail, it scales target column from range (0-100) to (0-1)  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a8871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classes_to_values(y):\n",
    "    y = [i / 100 for i in y]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba64977",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that calculates the Mean Absolute Error (MAE) and Mean Squared Error (MSE) between predictions and actual targets for train and test sets. \n",
    "    \n",
    "Although we have transformed our problem as a classification task, we assign classes to it as integers and compute metrics that are applied to regression tasks.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(eval_set,y_pred,y_test):\n",
    "    y_pred = classes_to_values(y_pred)\n",
    "    y_test = classes_to_values(y_test)\n",
    "    MAE = round(metrics.mean_absolute_error(y_test, y_pred),5)\n",
    "    print (f\"The Mean Abslolute Error (MAE) that have been calculated for {eval_set} set is: {MAE}\")\n",
    "    MSE = round(metrics.mean_squared_error(y_test, y_pred),5)\n",
    "    print (f\"The Mean Squared Error (MSE) that have been calculated for {eval_set} set is: {MSE}\")\n",
    "    return MAE,MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a893fb0",
   "metadata": {},
   "source": [
    "## PCA Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527b0cb",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that helps us to select the number of components for KPCA plotting explained variance.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e690149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_components_explain_variance(X_train,data_name,cores):\n",
    "    kpca = KernelPCA()\n",
    "    kpca_transform = kpca.fit_transform(X_train)\n",
    "    explained_variance = np.var(kpca_transform, axis=0)\n",
    "    explained_variance_ratio = explained_variance / np.sum(explained_variance)\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "    fig, ax = plt.subplots()\n",
    "    xi = np.arange(1, explained_variance_ratio.shape[0]+1, step=1)\n",
    "    y = np.cumsum(explained_variance_ratio)\n",
    "    plt.ylim(0.0,1.1)\n",
    "    plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.xticks(np.arange(0, 10, step=1)) #change from 0-based array index to 1-based human-readable label\n",
    "    plt.ylabel('Cumulative variance (%)')\n",
    "    plt.title('The number of components needed to explain variance')\n",
    "    plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "    plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n",
    "    plt.savefig('Exports/n_componets_Kernel_PCA_' + data_name + '.pdf')\n",
    "    ax.grid(axis='x')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ec440",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that applies GridSearch of 4-fold cross-validation on pipeline (KPCA + LDA) in order to find the best kernels and hyper-parameters of KPCA (it use best 'n_components' found from the above plot).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc113c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpca_random_grid_search_cv(X_train,y_train,cores,param_grid,n_comp):\n",
    "    clf = Pipeline([(\"kpca\", KernelPCA(n_components=n_comp)),(\"lda\", LinearDiscriminantAnalysis())])\n",
    "    KPCA_grid_search = GridSearchCV(clf, param_grid, cv=3, n_jobs=cores, verbose=3,scoring='neg_mean_absolute_error')\n",
    "    KPCA_grid_search.fit(X_train,y_train)\n",
    "    print(f\"\\nBest KPCA model have been fitting with the following parameters: {KPCA_grid_search.best_params_}\")\n",
    "    return KPCA_grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c07f40",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "A function that create a dataframe with cross validation results and save it to a csv file\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9103e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(KPCA_grid_search,project_path,data_name):\n",
    "    results = pd.DataFrame(KPCA_grid_search.cv_results_)\n",
    "    results = results.sort_values(by=['rank_test_score'])\n",
    "    results = results.reset_index()\n",
    "    results = results.drop(['index'], axis=1)\n",
    "    results.to_csv(project_path +'/Exports/CV_results_'+ data_name +'.csv')\n",
    "    print('\\nAll Cross Validation Results are described by the dataframe bellow:')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adca21cc",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that helps us to define the best hyper-parameters of LDA model \n",
    "    \n",
    "In more detail:\n",
    "- Fit a precomputed Kernel PCA model using the best hyper-parameters founded from GridSearch\n",
    "- Use KPCA outputs in order to fit an MultiOutput LDA model with the given param_grid\n",
    "- Calculate the necessary metrics in order to find the best hyper-parameters\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed02d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lda(X_train,X_test,y_train,y_test,KPCA_grid_search,param_grid,cores):\n",
    "    start = dt.now()\n",
    "    transformer = KPCA_grid_search.best_estimator_[0]\n",
    "    X_train_transformed = transformer.fit_transform(X_train)\n",
    "    X_test_transformed = transformer.transform(X_test)\n",
    " \n",
    "    LDA = LinearDiscriminantAnalysis(**param_grid)\n",
    "    LDA.fit(X_train_transformed, y_train)\n",
    "    running_secs = (dt.now() - start).seconds\n",
    "    print (f\"LDA + PCA model have fitted succesfully in {running_secs} seconds\")\n",
    "    \n",
    "    y_train_pred = LDA.predict(X_train_transformed)\n",
    "    train_MAE,train_MSE = calculate_metrics('train',y_train_pred,y_train)   \n",
    "    \n",
    "    y_pred = LDA.predict(X_test_transformed)\n",
    "    MAE,MSE = calculate_metrics('test',y_pred,y_test)\n",
    "    \n",
    "    return MAE,MSE,running_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ea6ce",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "A function that feed the above pipeline with different LDA hyper-parameters while saves the evaluation results.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ba4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_evaluation_results(X_train,X_test,y_train,y_test,KPCA_grid_search,param_grid,cores): \n",
    "    lda_results = []\n",
    "    for i in range(0,len(param_grid)):\n",
    "        print (f\"\\nParameters: {list(param_grid)[i]}\")\n",
    "        MAE,MSE,running_secs = evaluate_lda(X_train,X_test,y_train,y_test,KPCA_grid_search,param_grid[i],cores)\n",
    "        lda_results.append({'Parameters':param_grid[i],'MAE':MAE,'MSE':MSE,'Training Time':running_secs})\n",
    "    lda_results = pd.DataFrame(lda_results)\n",
    "    lda_results = lda_results.sort_values(by=['MAE'])\n",
    "    lda_results = lda_results.reset_index()\n",
    "    lda_results = lda_results.drop(['index'], axis=1)\n",
    "    return lda_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e94624d",
   "metadata": {},
   "source": [
    "## 1. Functionality Combinations for Parking Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43381bac",
   "metadata": {},
   "source": [
    "### 1.1 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd3671",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_set,test_set,train_targets,test_targets,train_mask,test_mask =  data_load(train_set_path_park,test_set_path_park,\n",
    "                                train_targets_path_park,test_targets_path_park,True,train_mask_path_park,test_mask_path_park,True,250,60)\n",
    "\n",
    "X_train,y_train = data_preprocess(train_set,train_targets,train_mask)\n",
    "X_test,y_test = data_preprocess(test_set,test_targets,test_mask)\n",
    "del(train_set,train_targets,train_mask,test_set,test_targets,test_mask)\n",
    "\n",
    "plot_components_explain_variance(X_train,'Parking',cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f599f9f",
   "metadata": {},
   "source": [
    "### 1.2 KPCA Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64509a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_param_grid = [{\"kpca__kernel\": ['poly'],\"kpca__gamma\": [0.3,0.4,0.5],\"kpca__degree\":[3,5]},\n",
    "              {\"kpca__kernel\": ['rbf'],\"kpca__gamma\": [0.3,0.4,0.5,1]},\n",
    "              {\"kpca__kernel\": ['sigmoid'],\"kpca__gamma\": [0.3,0.4,0.5],\"kpca__coef0\":[1,2]}]\n",
    "n_comp_parking = 6\n",
    "KPCA_grid_search = kpca_random_grid_search_cv(X_train,y_train,cores,kpca_param_grid,n_comp_parking)\n",
    "results_kpca = get_results_df(KPCA_grid_search,project_path,'Parking')\n",
    "results_kpca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe97b01",
   "metadata": {},
   "source": [
    "### 1.3 LDA evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0fbbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_parameters = [{\"solver\":['svd'],'store_covariance':[False,True],'tol':[0.05,0.5]},\n",
    "                {\"solver\":['lsqr','eigen'],'shrinkage':['auto',None,0.2,0.4]}]\n",
    "LDA_param_grid = ParameterGrid(lda_parameters)\n",
    "results_lda = lda_evaluation_results(X_train,X_test,y_train,y_test,KPCA_grid_search,LDA_param_grid,cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ac5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c50871",
   "metadata": {},
   "source": [
    "## 2. Functionality Combinations for ChickenPox Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c60cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess_chic(data_set,y):\n",
    "    for i in tqdm (range (0,len(data_set))):       \n",
    "        data_set[i] = data_set[i].join(y.iloc[:,i])\n",
    "        data_set[i] = data_set[i].set_axis([*data_set[i].columns[:-1], 'Target'], axis=1, inplace=False)\n",
    "        \n",
    "    data_set = pd.concat(data_set).reset_index()\n",
    "    \n",
    "    y = values_to_classes(data_set['Target'])\n",
    "    X = data_set.drop(['Target','index'], axis=1)\n",
    "    data_set = []\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e08e001",
   "metadata": {},
   "source": [
    "### 2.1 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ddcbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set,train_targets,test_targets,train_mask,test_mask =  data_load(train_set_path_chic,test_set_path_chic,\n",
    "                                train_targets_path_chic,test_targets_path_chic,False,train_mask_path_chic,test_mask_path_chic,False,200,50)\n",
    "\n",
    "X_train,y_train = data_preprocess_chic(train_set,train_targets)\n",
    "X_test,y_test = data_preprocess_chic(test_set,test_targets)\n",
    "del(train_set,train_targets,train_mask,test_set,test_targets,test_mask)\n",
    "plot_components_explain_variance(X_train,'Chickenpox',cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e9f93",
   "metadata": {},
   "source": [
    "### 2.2 KPCA Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_param_grid_chic = [{\"kpca__kernel\": ['poly'],\"kpca__gamma\": [0.3,0.4,0.5],\"kpca__degree\":[3,5]},\n",
    "              {\"kpca__kernel\": ['rbf'],\"kpca__gamma\": [0.3,0.4,0.5,1]},\n",
    "              {\"kpca__kernel\": ['sigmoid'],\"kpca__gamma\": [0.3,0.4,0.5],\"kpca__coef0\":[1,2]}]\n",
    "n_comp_chick = 3\n",
    "KPCA_grid_search_chic = kpca_random_grid_search_cv(X_train,y_train,cores,kpca_param_grid_chic,n_comp_chick)\n",
    "results_kpca_chic = get_results_df(KPCA_grid_search_chic,project_path,'Chickenpox')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07323648",
   "metadata": {},
   "source": [
    "### 1.3 LDA evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab93588",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_parameters_chic = [{\"solver\":['svd'],'store_covariance':[False,True],'tol':[0.1,0.001]},\n",
    "                {\"solver\":['lsqr','eigen'],'shrinkage':['auto',None,0.2,0.4]}]\n",
    "LDA_param_grid_chic = ParameterGrid(lda_parameters_chic)\n",
    "results_lda_chic = lda_evaluation_results(X_train,X_test,y_train,y_test,KPCA_grid_search_chic,LDA_param_grid_chic,cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lda_chic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full_ml",
   "language": "python",
   "name": "full_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
